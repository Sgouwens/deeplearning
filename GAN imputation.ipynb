{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import datasets\n",
    "\n",
    "from pytorchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The github repository og the GAIN author is found here: https://github.com/jsyoon0823/GAIN/blob/master/gain.py\n",
    "\n",
    "The networks (both discriminator and generator) have a very simple structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.ToImage(), \n",
    "    v2.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Lambda(lambda x: 2*x - 1)] \n",
    "    )\n",
    "\n",
    "train_data = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "test_data = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "\n",
    "# Getting a subset of the data for speed purposes\n",
    "num_samples = 60000\n",
    "indices = np.random.choice(len(train_data), num_samples, replace=False)\n",
    "train_subset = Subset(train_data, indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomAffine\n",
    "RandomAffine(degrees=(-10, 10), translate=(0, 0.1))\n",
    "\n",
    "dummydata = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator class\n",
    "class DiscriminatorConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorConv, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=2, padding=1), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1), \n",
    "            # nn.BatchNorm2d(64),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(1024, 1), \n",
    "            \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "\n",
    "# Generator class\n",
    "class GeneratorConv(nn.Module):\n",
    "    def __init__(self, z_dimension):\n",
    "        super(GeneratorConv, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(z_dimension, 128 * 7 * 7),\n",
    "            nn.BatchNorm1d(128 * 7 * 7),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Unflatten(1, (128, 7, 7)),  # 7 because it divides 28 (mnist resolution)\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(32, 1, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.Tanh()  \n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.network(z)\n",
    "\n",
    "class GAN(nn.Module):\n",
    "    pass\n",
    "    def __init__(self, generator, discriminator, latent_dimension, lossfunction):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.lossfunction = lossfunction\n",
    "        self.latent_dimension = latent_dimension #?\n",
    "\n",
    "\n",
    "    def forward_discriminator(self):\n",
    "        pass\n",
    "\n",
    "    def forward_generator(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self):\n",
    "        self.forward_discriminator()\n",
    "        self.forward_generator()\n",
    "\n",
    "    def save_parameters(self):\n",
    "        torch.save(self.generator.state_dict(), \"generate_1.pth\")\n",
    "        torch.save(self.discriminator.state_dict(), \"discriminate_1.pth\")\n",
    "\n",
    "    def print_layer_summary(self):\n",
    "        summary(model=self.generator, input_size=(1, self.latent_dimension))\n",
    "        summary(model=self.discriminator, input_size=(1, 28, 28))\n",
    "\n",
    "    def plot_training_loss(self):\n",
    "        plt.plot(discriminate_loss[0:])\n",
    "        plt.plot(generate_loss[0:])\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend([\"Discriminator\", \"Generator\"])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_discriminator = 2e-4\n",
    "lr_generator = 4e-4\n",
    "noise_dimension = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lossfunction = nn.BCELoss()\n",
    "\n",
    "generate = GeneratorConv(noise_dimension).to(device)\n",
    "discriminate = DiscriminatorConv().to(device)\n",
    "\n",
    "optimizer_gen = optim.Adam(generate.parameters(), lr=lr_generator, betas=(0.5, 0.999))\n",
    "optimizer_disc = optim.Adam(discriminate.parameters(), lr=lr_discriminator, betas=(0.5, 0.999))\n",
    "\n",
    "noise_general = torch.randn(noise_dimension, noise_dimension, device=device)\n",
    "\n",
    "discriminate_loss, generate_loss = [], []\n",
    "epoch_current = 0\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(discriminate), count_parameters(generate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1\n",
    "epochs = 30\n",
    "\n",
    "total_batches = len(train_loader)\n",
    "real_label_noise = 0.95 + 0.05 * torch.rand(batch_size, 1, device=device) # I think I switched the labels.. and it works and does not work the other way around.. ???\n",
    "fake_label_noise = 0.05 * torch.rand(batch_size, 1, device=device)\n",
    "\n",
    "for epoch in range(epoch_current, epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Initialize cumulative loss values for the epoch\n",
    "    running_loss_disc = 0.0\n",
    "    running_loss_gen = 0.0\n",
    "\n",
    "    # Updating the Generator \n",
    "    for i, batch in enumerate(train_loader):\n",
    "\n",
    "        #############################################################################################################################\n",
    "        ### Update the discriminator distribution. This van also be done (K=1) times. K is a hyperparameter in (Goodfellow, 2014) ###\n",
    "        optimizer_disc.zero_grad()\n",
    "        noise = torch.randn(batch_size, noise_dimension, device=device)\n",
    "\n",
    "        real_images = batch[0].to(device)\n",
    "        fake_images = generate(noise).detach() # detach() so that gradients are not passed back to the generator when updating the discriminator.\n",
    "        real_images_disc = discriminate(real_images)\n",
    "        fake_images_disc = discriminate(fake_images)\n",
    "\n",
    "        # Computing the loss function (As in Algorithm 1 in Goodfellow)\n",
    "        loss_data = lossfunction(real_images_disc + 1e-8, fake_label_noise)        # E log   D(  x)\n",
    "        loss_generated = lossfunction(fake_images_disc + 1e-8, real_label_noise)   # E log(1-D(G(z))\n",
    "        loss_discriminator = loss_data + loss_generated\n",
    "\n",
    "        # Keeping track of the loss and performing backward propagation\n",
    "        running_loss_disc += loss_discriminator.item()\n",
    "        loss_discriminator.backward()\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################\n",
    "        ### Updating the generator ###\n",
    "        optimizer_gen.zero_grad()\n",
    "\n",
    "        noise = torch.randn(batch_size, noise_dimension, device=device) # Does this one need to be different than the noise of beginning of loop?\n",
    "        fake_images = generate(noise)\n",
    "        fake_images_disc = discriminate(fake_images)\n",
    "        loss_generator = lossfunction(fake_images_disc, torch.zeros(batch_size, 1, device=device))\n",
    "\n",
    "        loss_generator.backward()\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        running_loss_gen += loss_generator.item()\n",
    "\n",
    "    avg_loss_disc = running_loss_disc / (K * total_batches)\n",
    "    avg_loss_gen = running_loss_gen / total_batches\n",
    "\n",
    "    discriminate_loss.append(avg_loss_disc)\n",
    "    generate_loss.append(avg_loss_gen)\n",
    "    \n",
    "    # Display the epoch progress\n",
    "    progress = (epoch + 1) / epochs * 100\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}] - {progress:.2f}% complete | \"\n",
    "          f\"Discriminator Loss: {avg_loss_disc:.4f} | Generator Loss: {avg_loss_gen:.4f} | \"\n",
    "          f\"Time: {time.time() - start_time:.2f}s\")\n",
    "    \n",
    "    # Show every few epochs how the fixed noise is generates into new images and save it\n",
    "    if (epoch+1) % 2 == 0:\n",
    "        fake_images = generate(noise_general)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Fake Images at Epoch {epoch + 1}\")\n",
    "        plt.imshow(vutils.make_grid(fake_images[:64], padding=2, normalize=True).cpu().numpy().transpose((1, 2, 0)))\n",
    "        plt.savefig(f\"{os.getcwd()}/images/mnist_gam_Fake Images at Epoch {epoch + 1}.png\")\n",
    "\n",
    "    epoch_current += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = batch[0][:64] \n",
    "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = images[i].squeeze().numpy()  # Remove extra dimension and convert to numpy array\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.axis('off')  # Hide axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # all_images = torch.cat([real_images, fake_images], axis=0)\n",
    "        # all_images_disc = discriminate(all_images)\n",
    "        # labels = torch.cat([real_label_noise, fake_label_noise])\n",
    "        # loss_discriminator = lossfunction(all_images_disc, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(discriminate_loss[0:])\n",
    "plt.plot(generate_loss[0:])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Discriminator\", \"Generator\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use MNIST on VAE's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8, 7, 7])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 78\u001b[0m\n\u001b[0;32m     76\u001b[0m lol\u001b[38;5;241m.\u001b[39mshape, wut\u001b[38;5;241m.\u001b[39mshape, vae\u001b[38;5;241m.\u001b[39mdecode(yuh)\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     77\u001b[0m test \u001b[38;5;241m=\u001b[39m vae\u001b[38;5;241m.\u001b[39mencoder(torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m))\n\u001b[1;32m---> 78\u001b[0m test\u001b[38;5;241m.\u001b[39mshape, test\u001b[38;5;241m.\u001b[39mview(\u001b[43mtt\u001b[49m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tt' is not defined"
     ]
    }
   ],
   "source": [
    "class VAEMNIST(nn.Module):\n",
    "    def __init__(self, latent_dim=64, first_channel=16):\n",
    "        super(VAEMNIST, self).__init__()\n",
    "        \n",
    "        self.first_channel = first_channel\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Calculate sizes for proper dimensionality tracking\n",
    "        # Input: 100x100\n",
    "        # After 2 stride-2 convolutions: 100 -> 50 -> 25\n",
    "        self.dim = 7\n",
    "\n",
    "        # Encoder: convolutional layers for grid-like data\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, self.first_channel, kernel_size=3, stride=2, padding=1),  # 100x100 -> 50x50\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.first_channel, 2*self.first_channel, kernel_size=3, stride=2, padding=1),  # 50x50 -> 25x25\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.flatten_size = 2*self.first_channel * self.dim**2\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.flatten_size, self.latent_dim)  # Mean in latent space\n",
    "        self.fc2 = nn.Linear(self.flatten_size, self.latent_dim)  # Log variance        \n",
    "        self.fc3 = nn.Linear(self.latent_dim, 2 * self.first_channel * self.dim**2)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2*self.first_channel, self.first_channel, kernel_size=3, stride=2, padding=1, output_padding=1),  # 25x25 -> 50x50\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(self.first_channel, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  # 50x50 -> 100x100\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten: 32 x 2*first_channel*25*25\n",
    "        mu = self.fc1(x)           # Mean\n",
    "        logvar = self.fc2(x)       # Log variance\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)  # Standard deviation\n",
    "        eps = torch.randn_like(std)  # Random noise\n",
    "        return mu + eps * std  # Reparameterization trick\n",
    "    \n",
    "    def decode(self, z):\n",
    "        x = self.fc3(z)  # (B, latent_dim) -> (B, 2*first_channel*25*25)\n",
    "        # Reshape for the decoder: batch_size x channels x height x width\n",
    "        x = x.view(-1, 2*self.first_channel, self.dim, self.dim)\n",
    "        return self.decoder(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)  # Get mean and log variance\n",
    "        z = self.reparameterize(mu, logvar)  # Sample from the latent space\n",
    "        reconstructed_x = self.decode(z)  # Decode back to original space\n",
    "        return reconstructed_x, mu, logvar\n",
    "    \n",
    "    def loss_function(self, recon_x, x, mu, logvar, beta=1.0):\n",
    "        MSE = F.mse_loss(recon_x, x, reduction='sum')  \n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return MSE + beta * KLD\n",
    "\n",
    "    def summary(self):\n",
    "        pass\n",
    "\n",
    "device = \"cpu\"\n",
    "vae = VAEMNIST(latent_dim=64, first_channel=4).to(device) \n",
    "\n",
    "# For testing purposes\n",
    "with torch.no_grad():\n",
    "    tester = torch.randn(batch_size, 1, 28, 28)\n",
    "    lol, wut = vae.encode(tester)\n",
    "    yuh = vae.reparameterize(lol,wut)\n",
    "    vae.decode(yuh).shape\n",
    "    print(vae.encoder(torch.randn(batch_size, 1, 28, 28)).shape)\n",
    "    lol.shape, wut.shape, vae.decode(yuh).shape\n",
    "    test = vae.encoder(torch.randn(batch_size, 1, 28, 28))\n",
    "    test.shape, test.view(tt.size(0), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "train_data = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True)\n",
    "test_data = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False)\n",
    "\n",
    "# Getting a subset of the data for speed purposes\n",
    "num_samples = 60000\n",
    "indices = np.random.choice(len(train_data), num_samples, replace=False)\n",
    "train_subset = Subset(train_data, indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MNIST' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvutils\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[1;32m---> 18\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(vae\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gouwenss\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:205\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "File \u001b[1;32mc:\\Users\\gouwenss\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:206\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m--> 206\u001b[0m         \u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors\n\u001b[0;32m    207\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MNIST' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-4)\n",
    " \n",
    "num_epochs = 2000\n",
    "print_every = 10\n",
    "\n",
    "def lr_lambda(epoch):\n",
    "    start_lr = 0.01\n",
    "    end_lr = 0.0001\n",
    "    total_steps = 100\n",
    "    return (end_lr - start_lr) * (epoch / total_steps) + start_lr  # Linear decay\n",
    "\n",
    "# Define LambdaLR scheduler\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    vae.train()  # Training mode\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, ) in enumerate(train_loader):\n",
    "        # Move data to the appropriate device\n",
    "        data = data.to(device)\n",
    "        data = data.unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = vae(data)\n",
    "        loss = vae.loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % print_every == 0:\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs} *1e-6], Loss: {epoch_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
