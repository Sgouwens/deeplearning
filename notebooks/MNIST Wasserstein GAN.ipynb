{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document we will explore a number of difference GANs. All have the aim to produce new samples of hand-written MNIST digits. We will start easy with the model of Goodfellow (2016) and gradually we will update the model to more advanced architectures.\n",
    "\n",
    "1) Regular GAN (Goodfellow, 2016)\n",
    "2) Regular GAN with convolutional layers\n",
    "3) -> Wasserstein GAN (Arjovsky, 2017)\n",
    "4) -> Wasserstein GAN with convolutional layers\n",
    "\n",
    "This notebook focusses on implementation of the Wasserstein GAN. An improvement on the regular GAN that proposes a new loss function for the critic. This loss function makes use of the Earth Movers distance:\n",
    "\n",
    "$$W(P||Q) = \\inf_{\\gamma\\in\\Pi(P,Q)E_{(x,y)\\sim\\gamma}}\\big[||x-y||\\big]=\\sup_{||f||\\leq1}(E_{x\\sim P}f(x) - E_{x\\sim Q}f(x))$$\n",
    "\n",
    "where $P$ and $Q$ are substituted by .....\n",
    "\n",
    "We start off by loading the MNIST data and transform them. Due to the fact that we work on a CPU, we limit the data to 60_000 samples to keep the computations managable.\n",
    "\n",
    "Furthermore, the WGAN-GP (gradient penalty) is implemented. This has the loss function\n",
    "$$L = E_{x\\sim P_g}D(x) - E_{x\\sim P_r}D(x) + \\lambda E_{\\hat x\\sim P_{\\hat x}}((||\\nabla_{\\hat x}D(\\hat x)||_2-1)^2)$$\n",
    "where the hyperparameter $\\lambda$ is often set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "centering_fun = lambda x: x.view(-1) - 0.5\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "test_data = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "\n",
    "num_samples = 60000\n",
    "indices = np.random.choice(len(train_data), num_samples, replace=False)\n",
    "train_subset = Subset(train_data, indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we make the discriminator. This is the network that should be able to distinguish the items from the original dataset from fake generated data. It should resemble a function $D:x\\to(0,1)$ In this case, $x$ are vectors that describe a number in the MNIST dataset.\n",
    "\n",
    "The "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dimension = 64\n",
    "\n",
    "# Discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "\n",
    "# Generator class\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\"\"\"\n",
    "    def __init__(self, z_dimension):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(z_dimension, 128), # or 128?\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(512, 784),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.network(z).view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a discriminator network using convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "epochs = 1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lossfunction = nn.BCELoss()\n",
    "\n",
    "generate = Generator(noise_dimension).to(device)\n",
    "discriminate = Discriminator().to(device)\n",
    "\n",
    "optimizer_gen = optim.Adam(generate.parameters(), lr=lr)\n",
    "optimizer_disc = optim.Adam(discriminate.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we code the training loop.\n",
    "\n",
    "$$E_{x\\sim p_{data}}\\log D(x) + E_{z\\sim p_{z}}\\log(1- D(G(z)))$$\n",
    "\n",
    "The left expectation is the real part, the right expectation is called the fake part\n",
    "\n",
    "BCELoss $(x,y) = \\frac{1}{n}\\sum_{i=1}^n[y_i\\log(x_i) +(1-y_i)\\log(1-x_i)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - 2.00% complete | Discriminator Loss: 0.0591 | Generator Loss: 0.0394\n",
      "Epoch [2/50] - 4.00% complete | Discriminator Loss: 0.1798 | Generator Loss: 0.1662\n",
      "Epoch [3/50] - 6.00% complete | Discriminator Loss: 0.1473 | Generator Loss: 0.0351\n",
      "Epoch [4/50] - 8.00% complete | Discriminator Loss: 0.1355 | Generator Loss: 0.1090\n",
      "Epoch [5/50] - 10.00% complete | Discriminator Loss: 0.0498 | Generator Loss: 0.1468\n",
      "Epoch [6/50] - 12.00% complete | Discriminator Loss: 0.0873 | Generator Loss: 0.4993\n",
      "Epoch [7/50] - 14.00% complete | Discriminator Loss: 0.0836 | Generator Loss: 0.1088\n",
      "Epoch [8/50] - 16.00% complete | Discriminator Loss: 0.1511 | Generator Loss: 0.3205\n",
      "Epoch [9/50] - 18.00% complete | Discriminator Loss: 0.0746 | Generator Loss: 3.0873\n",
      "Epoch [10/50] - 20.00% complete | Discriminator Loss: 0.0760 | Generator Loss: 0.3766\n",
      "Epoch [11/50] - 22.00% complete | Discriminator Loss: 0.0408 | Generator Loss: 0.0399\n",
      "Epoch [12/50] - 24.00% complete | Discriminator Loss: 0.0631 | Generator Loss: 0.1967\n",
      "Epoch [13/50] - 26.00% complete | Discriminator Loss: 0.0406 | Generator Loss: 0.0978\n",
      "Epoch [14/50] - 28.00% complete | Discriminator Loss: 0.0656 | Generator Loss: 0.2692\n",
      "Epoch [15/50] - 30.00% complete | Discriminator Loss: 0.0583 | Generator Loss: 0.1016\n",
      "Epoch [16/50] - 32.00% complete | Discriminator Loss: 0.0525 | Generator Loss: 0.0425\n",
      "Epoch [17/50] - 34.00% complete | Discriminator Loss: 0.0547 | Generator Loss: 0.0375\n",
      "Epoch [18/50] - 36.00% complete | Discriminator Loss: 0.0589 | Generator Loss: 0.0518\n",
      "Epoch [19/50] - 38.00% complete | Discriminator Loss: 0.0577 | Generator Loss: 0.0417\n",
      "Epoch [20/50] - 40.00% complete | Discriminator Loss: 0.0629 | Generator Loss: 0.0635\n",
      "Epoch [21/50] - 42.00% complete | Discriminator Loss: 0.0448 | Generator Loss: 0.0442\n",
      "Epoch [22/50] - 44.00% complete | Discriminator Loss: 0.0544 | Generator Loss: 0.0483\n"
     ]
    }
   ],
   "source": [
    "K = 2\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Total number of loops\n",
    "\n",
    "    # Initialize cumulative loss values for the epoch\n",
    "    total_batches = len(train_loader)\n",
    "    running_loss_disc = 0.0\n",
    "    running_loss_gen = 0.0\n",
    "\n",
    "    for k in range(K):\n",
    "        # Update the generating distribution K times before a single update of the discriminator\n",
    "\n",
    "        for batch in train_loader:\n",
    "            # Apply minibatch gradient descent\n",
    "            # Generate fake images for updating the generator\n",
    "            optimizer_disc.zero_grad()\n",
    "\n",
    "            batch_size = batch[0].size(0)\n",
    "            real_images = batch[0].to(device) ###########################\n",
    "\n",
    "            noise = torch.randn(batch_size, noise_dimension, device=device)           #             z\n",
    "            fake_images = generate(noise)                                             #           G(z)\n",
    "\n",
    "            fake_images_disc = discriminate(fake_images.detach())                     #         D(G(z))\n",
    "            real_images_disc = discriminate(real_images)\n",
    "\n",
    "            # Make some helper values that help selecting the correct part of BCELoss\n",
    "            y_ones = torch.ones(batch_size, 1, device=device)\n",
    "            y_zeros = torch.zeros(batch_size, 1, device=device)\n",
    "            \n",
    "            # Computing the loss function (As in Algorithm 1 in Goodfellow)\n",
    "            loss_data = lossfunction(real_images_disc, y_zeros)                       # E log D(x)\n",
    "            loss_generated = lossfunction(fake_images_disc, y_ones)                   # E log(1-D(G(z))\n",
    "            loss_discriminator = loss_data + loss_generated\n",
    "\n",
    "            # Update the discriminator using 'loss'.\n",
    "            loss_discriminator.backward()\n",
    "            optimizer_disc.step()\n",
    "\n",
    "            running_loss_disc += loss_discriminator.item()\n",
    "            \n",
    "    # Update the generator using newly generated \n",
    "    for i, batch in enumerate(train_loader):\n",
    "        \n",
    "        optimizer_gen.zero_grad()\n",
    "\n",
    "        noise = torch.randn(batch_size, noise_dimension, device=device)\n",
    "        fake_images = generate(noise)\n",
    "        fake_images_disc = discriminate(fake_images)\n",
    "\n",
    "        # Compute loss of the discriminator\n",
    "        loss_generator = lossfunction(fake_images_disc, y_zeros)\n",
    "        loss_generator.backward()\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        running_loss_gen += loss_generator.item()\n",
    "\n",
    "    avg_loss_disc = running_loss_disc / (K * total_batches)\n",
    "    avg_loss_gen = running_loss_gen / total_batches\n",
    "\n",
    "    # Display the epoch progress\n",
    "    progress = (epoch + 1) / epochs * 100\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}] - {progress:.2f}% complete | \"\n",
    "          f\"Discriminator Loss: {avg_loss_disc:.4f} | Generator Loss: {avg_loss_gen:.4f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 50 epochs the sampled digits start representing digits, beautiful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFake Images at Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mepoch\u001b[49m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(vutils\u001b[38;5;241m.\u001b[39mmake_grid(fake_images[:\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)))\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epoch' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAFICAYAAADAnk9nAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABgpJREFUeJzt1jEBACAMwDDAv+fhAo4mCnp2z8wsAAAyzu8AAADeMoAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIMIABAjAEEAIgxgAAAMQYQACDGAAIAxBhAAIAYAwgAEGMAAQBiDCAAQIwBBACIMYAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIMIABAjAEEAIgxgAAAMQYQACDGAAIAxBhAAIAYAwgAEGMAAQBiDCAAQIwBBACIMYAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIMIABAjAEEAIgxgAAAMQYQACDGAAIAxBhAAIAYAwgAEGMAAQBiDCAAQIwBBACIMYAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIMIABAjAEEAIgxgAAAMQYQACDGAAIAxBhAAIAYAwgAEGMAAQBiDCAAQIwBBACIMYAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIMIABAjAEEAIgxgAAAMQYQACDGAAIAxBhAAIAYAwgAEGMAAQBiDCAAQIwBBACIMYAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIMIABAjAEEAIgxgAAAMQYQACDGAAIAxBhAAIAYAwgAEGMAAQBiDCAAQIwBBACIMYAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIMIABAjAEEAIgxgAAAMQYQACDGAAIAxBhAAIAYAwgAEGMAAQBiDCAAQIwBBACIMYAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIMIABAjAEEAIgxgAAAMQYQACDGAAIAxBhAAIAYAwgAEGMAAQBiDCAAQIwBBACIMYAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIMIABAjAEEAIgxgAAAMQYQACDGAAIAxBhAAIAYAwgAEGMAAQBiDCAAQIwBBACIMYAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIMIABAjAEEAIgxgAAAMQYQACDGAAIAxBhAAIAYAwgAEGMAAQBiDCAAQIwBBACIMYAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIMIABAjAEEAIgxgAAAMQYQACDGAAIAxBhAAIAYAwgAEGMAAQBiDCAAQIwBBACIMYAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIMIABAjAEEAIgxgAAAMQYQACDGAAIAxBhAAIAYAwgAEGMAAQBiDCAAQIwBBACIMYAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIMIABAjAEEAIgxgAAAMQYQACDGAAIAxBhAAIAYAwgAEGMAAQBiDCAAQIwBBACIMYAAADEGEAAgxgACAMQYQACAGAMIABBjAAEAYgwgAECMAQQAiDGAAAAxBhAAIMYAAgDEGEAAgBgDCAAQYwABAGIuu8QGjMiAqI0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Fake Images at Epoch {epoch + 1}\")\n",
    "plt.imshow(vutils.make_grid(fake_images[:4*8], padding=2, normalize=True).cpu().numpy().transpose((1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, both the discriminator and the generator are fully connected NN's. For image data, it may be more interesting to make the discriminator into a convolutional NN, and the generator a deconvolutional neural net.\n",
    "\n",
    "$$D:R^{784}\\to[0,1]$$\n",
    "$$G:R^{32}\\to X \\subseteq R^{784}$$\n",
    "\n",
    "Where $X$ is the image-space.\n",
    "\n",
    "For convolutional networks, we use a different transformer. First of all, we use RandomAffine to augment data. All pixels can be shifted up and down by a range of 10% of the pixels. They can also be rotated and should still resemble a digit. We also transform the digit values to the interval [0,1] rather than [-0.5, 0.5] by applying a monotonic bijective mapping $\\varphi(x)=2x+1$ such that $\\varphi([-0.5, 0.5])=[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.ToImage(), \n",
    "    v2.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Lambda(lambda x: 2*x - 1)] \n",
    "    )\n",
    "\n",
    "train_data = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "test_data = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "\n",
    "# Getting a subset of the data for speed purposes\n",
    "num_samples = 60000\n",
    "indices = np.random.choice(len(train_data), num_samples, replace=False)\n",
    "train_subset = Subset(train_data, indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both networks are kept quite small. The discriminator consists of three convolutional layers but we generate up to 64 channels. The generator uses inverted convolution to upsample the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator class\n",
    "class DiscriminatorConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorConv, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=2, padding=1), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1), \n",
    "            # nn.BatchNorm2d(64),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(1024, 1), \n",
    "            \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "\n",
    "# Generator class\n",
    "class GeneratorConv(nn.Module):\n",
    "    def __init__(self, z_dimension):\n",
    "        super(GeneratorConv, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(z_dimension, 128 * 7 * 7),\n",
    "            nn.BatchNorm1d(128 * 7 * 7),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Unflatten(1, (128, 7, 7)),  # 7 because it divides 28 (mnist resolution)\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(32, 1, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.Tanh()  \n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.network(z)\n",
    "\n",
    "class GAN(nn.Module):\n",
    "    pass\n",
    "    def __init__(self, generator, discriminator, latent_dimension, lossfunction):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.lossfunction = lossfunction\n",
    "        self.latent_dimension = latent_dimension #?\n",
    "\n",
    "\n",
    "    def forward_discriminator(self):\n",
    "        pass\n",
    "\n",
    "    def forward_generator(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self):\n",
    "        self.forward_discriminator()\n",
    "        self.forward_generator()\n",
    "\n",
    "    def save_parameters(self):\n",
    "        torch.save(self.generator.state_dict(), \"generate_1.pth\")\n",
    "        torch.save(self.discriminator.state_dict(), \"discriminate_1.pth\")\n",
    "\n",
    "    def print_layer_summary(self):\n",
    "        summary(model=self.generator, input_size=(1, self.latent_dimension))\n",
    "        summary(model=self.discriminator, input_size=(1, 28, 28))\n",
    "\n",
    "    def plot_training_loss(self):\n",
    "        plt.plot(discriminate_loss[0:])\n",
    "        plt.plot(generate_loss[0:])\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend([\"Discriminator\", \"Generator\"])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "transform = v2.Compose([ # transform is anders\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True)])\n",
    "\n",
    "train_data = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "test_data = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "\n",
    "# Getting a subset of the data for speed purposes\n",
    "num_samples = 60000\n",
    "indices = np.random.choice(len(train_data), num_samples, replace=False)\n",
    "train_subset = Subset(train_data, indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "epochs = 1\n",
    "\n",
    "generate = GeneratorConv(noise_dimension).to(device)\n",
    "discriminate = DiscriminatorConv().to(device)\n",
    "\n",
    "optimizer_gen = optim.Adam(generate.parameters(), lr=lr)\n",
    "optimizer_disc = optim.Adam(discriminate.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128, 16])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m y_zeros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(batch_size, \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Computing the loss function (As in Algorithm 1 in Goodfellow)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m loss_data \u001b[38;5;241m=\u001b[39m \u001b[43mlossfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_images_disc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_zeros\u001b[49m\u001b[43m)\u001b[49m                       \u001b[38;5;66;03m# E log D(x)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m loss_generated \u001b[38;5;241m=\u001b[39m lossfunction(fake_images_disc, y_ones)                   \u001b[38;5;66;03m# E log(1-D(G(z))\u001b[39;00m\n\u001b[0;32m     36\u001b[0m loss_discriminator \u001b[38;5;241m=\u001b[39m loss_data \u001b[38;5;241m+\u001b[39m loss_generated\n",
      "File \u001b[1;32mc:\\Users\\gouwenss\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gouwenss\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gouwenss\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gouwenss\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\functional.py:3145\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3143\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[1;32m-> 3145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3148\u001b[0m     )\n\u001b[0;32m   3150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3151\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128, 16])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "K = 2\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Total number of loops\n",
    "\n",
    "    # Initialize cumulative loss values for the epoch\n",
    "    total_batches = len(train_loader)\n",
    "    running_loss_disc = 0.0\n",
    "    running_loss_gen = 0.0\n",
    "\n",
    "    for k in range(K):\n",
    "        # Update the generating distribution K times before a single update of the discriminator\n",
    "\n",
    "        for batch in train_loader:\n",
    "            # Apply minibatch gradient descent\n",
    "            # Generate fake images for updating the generator\n",
    "            optimizer_disc.zero_grad()\n",
    "\n",
    "            batch_size = batch[0].size(0)\n",
    "            real_images = batch[0].to(device) ###########################\n",
    "\n",
    "            noise = torch.randn(batch_size, noise_dimension, device=device)           #             z\n",
    "            fake_images = generate(noise)                                             #           G(z)\n",
    "\n",
    "            fake_images_disc = discriminate(fake_images.detach())                     #         D(G(z))\n",
    "            real_images_disc = discriminate(real_images)\n",
    "\n",
    "            # Make some helper values that help selecting the correct part of BCELoss\n",
    "            y_ones = torch.ones(batch_size, 1, device=device)\n",
    "            y_zeros = torch.zeros(batch_size, 1, device=device)\n",
    "            \n",
    "            # Computing the loss function (As in Algorithm 1 in Goodfellow)\n",
    "            loss_data = lossfunction(real_images_disc, y_zeros)                       # E log D(x)\n",
    "            loss_generated = lossfunction(fake_images_disc, y_ones)                   # E log(1-D(G(z))\n",
    "            loss_discriminator = loss_data + loss_generated\n",
    "\n",
    "            # Update the discriminator using 'loss'.\n",
    "            loss_discriminator.backward()\n",
    "            optimizer_disc.step()\n",
    "\n",
    "            running_loss_disc += loss_discriminator.item()\n",
    "            \n",
    "    # Update the generator using newly generated \n",
    "    for i, batch in enumerate(train_loader):\n",
    "        \n",
    "        optimizer_gen.zero_grad()\n",
    "\n",
    "        noise = torch.randn(batch_size, noise_dimension, device=device)\n",
    "        fake_images = generate(noise)\n",
    "        fake_images_disc = discriminate(fake_images)\n",
    "\n",
    "        # Compute loss of the discriminator\n",
    "        loss_generator = lossfunction(fake_images_disc, y_zeros)\n",
    "        loss_generator.backward()\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        running_loss_gen += loss_generator.item()\n",
    "\n",
    "    avg_loss_disc = running_loss_disc / (K * total_batches)\n",
    "    avg_loss_gen = running_loss_gen / total_batches\n",
    "\n",
    "    # Display the epoch progress\n",
    "    progress = (epoch + 1) / epochs * 100\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}] - {progress:.2f}% complete | \"\n",
    "          f\"Discriminator Loss: {avg_loss_disc:.4f} | Generator Loss: {avg_loss_gen:.4f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Fake Images at Epoch {epoch + 1}\")\n",
    "plt.imshow(vutils.make_grid(fake_images[:64], padding=2, normalize=True).cpu().numpy().transpose((1, 2, 0)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
